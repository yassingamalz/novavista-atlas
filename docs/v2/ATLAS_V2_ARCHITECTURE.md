# ğŸ—ï¸ NovaVista Atlas v2 - Architecture & Design

## ğŸ“Œ Executive Summary

**NovaVista Atlas v2** represents a fundamental architectural shift from classical computer vision to a **hybrid deep learning + geometry approach**. This document outlines the technical architecture, design decisions, and implementation strategy.

---

## ğŸ”„ Evolution: v1 â†’ v2

### v1 Architecture (Classical CV)
```
[Input Frame]
    â†“
[HSV Color Thresholding] â† âŒ Brittle, lighting-dependent
    â†“
[Hough Line Detection]
    â†“
[ORB Feature Matching]
    â†“
[Homography Estimation]
    â†“
[Output]
```

**Problems:**
- HSV thresholds break with lighting changes
- Shadows fragment the field mask
- Different grass colors (dry vs wet) cause failures
- Advertising boards confuse line detection
- ~60-70% reliability in production

### v2 Architecture (Hybrid DL + Geometry)
```
[Input Frame]
    â†“
[Deep Learning Segmentation (UNet)] â† âœ… Robust, learned features
    â†“
[Mask Refinement (OpenCV)]
    â†“
[Line Detection (Hough on masked region)]
    â†“
[Keypoint Extraction (Line intersections)]
    â†“
[Homography Estimation (RANSAC)]
    â†“
[Temporal Smoothing (EMA/Kalman)]
    â†“
[Validated Output]
```

**Improvements:**
- Segmentation: ~90%+ IoU vs 60-70% in v1
- Lighting robustness: Works day/night/shadows
- Stadium agnostic: Adapts to any grass color
- Temporal stability: Smooth frame-to-frame
- ~95%+ production reliability target

---

## ğŸ§© System Components

### 1. **Segmentation Module** (NEW in v2)

**Purpose:** Isolate pitch area using learned visual features

**Implementation:**
- **Model:** UNet-Lite (lightweight encoder-decoder)
- **Input:** 512Ã—512 RGB frame (resized)
- **Output:** Binary mask (pitch=1, background=0)
- **Training:** ~500-1000 annotated frames from Egyptian league
- **Inference:** ~15ms on GPU, ~80ms on CPU

**File Location:**
```
atlas/v2/segmentation/
â”œâ”€â”€ model_unet.py       # UNet architecture
â”œâ”€â”€ dataset.py          # Data loader
â”œâ”€â”€ train.py            # Training script
â”œâ”€â”€ inference.py        # Inference wrapper
â””â”€â”€ weights/            # Trained model weights
```

**Key Methods:**
```python
class PitchSegmenter:
    def __init__(self, model_path: str):
        """Load trained UNet model"""
        
    def segment(self, frame: np.ndarray) -> np.ndarray:
        """
        Args:
            frame: RGB image (any size)
        Returns:
            Binary mask (same size as input)
        """
```

---

### 2. **Mask Refinement Module** (ENHANCED in v2)

**Purpose:** Clean up DL predictions using morphology

**Changes from v1:**
- Now operates on DL mask instead of HSV mask
- More aggressive noise removal
- Convex hull approximation for smooth boundaries

**Implementation:**
```python
def refine_mask(dl_mask: np.ndarray) -> np.ndarray:
    """
    Post-process deep learning mask
    
    Steps:
    1. Morphological opening (remove small noise)
    2. Morphological closing (fill small holes)
    3. Keep largest connected component
    4. Optional: Convex hull for smooth boundary
    """
```

---

### 3. **Line Detection Module** (UNCHANGED from v1)

**Purpose:** Detect pitch markings within segmented area

**Key Difference:** Now operates on **masked DL output** instead of HSV output
- Same Hough transform parameters
- Same line filtering logic
- Better results due to cleaner input mask

---

### 4. **Homography Estimation** (ENHANCED in v2)

**New Features:**
- **Temporal smoothing:** EMA filter on homography matrix
- **Quality validation:** Reject bad homographies automatically
- **Fallback mechanism:** Use previous good homography if current fails

**Implementation:**
```python
class HomographyEstimatorV2:
    def __init__(self, alpha=0.3):
        """
        alpha: EMA smoothing factor
        """
        self.H_prev = None
        
    def estimate_smooth(self, 
                       keypoints_img: np.ndarray,
                       keypoints_template: np.ndarray) -> Tuple[np.ndarray, float]:
        """
        Estimate homography with temporal smoothing
        
        Returns:
            H: 3Ã—3 matrix
            quality_score: float [0,1]
        """
```

---

### 5. **Validation Module** (NEW in v2)

**Purpose:** Assess homography quality and trigger fallback

**Checks:**
1. Inlier ratio > 0.6 (from RANSAC)
2. All 4 corners project inside image bounds
3. Mask overlap between projected template and segmentation > 0.7
4. Homography determinant > 0 (non-degenerate)

**Output:** Quality score âˆˆ [0, 1]

---

## ğŸ“Š Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INPUT FRAME                             â”‚
â”‚                     (1920Ã—1080 RGB)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  1. SEGMENTATION (UNet)                         â”‚
â”‚  â€¢ Resize to 512Ã—512                                            â”‚
â”‚  â€¢ Normalize RGB                                                â”‚
â”‚  â€¢ Forward pass through model                                   â”‚
â”‚  â€¢ Upsample mask to original size                               â”‚
â”‚  Output: Binary mask (HÃ—W)                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  2. MASK REFINEMENT                             â”‚
â”‚  â€¢ Morphological open/close                                     â”‚
â”‚  â€¢ Largest connected component                                  â”‚
â”‚  â€¢ Optional convex hull                                         â”‚
â”‚  Output: Refined binary mask                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  3. LINE DETECTION                              â”‚
â”‚  â€¢ Apply mask to frame                                          â”‚
â”‚  â€¢ Canny edge detection                                         â”‚
â”‚  â€¢ Hough line transform                                         â”‚
â”‚  â€¢ Filter by length/angle                                       â”‚
â”‚  Output: List of line segments                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  4. KEYPOINT EXTRACTION                         â”‚
â”‚  â€¢ Compute line intersections                                   â”‚
â”‚  â€¢ Filter inside mask                                           â”‚
â”‚  â€¢ Select 4 strongest corners                                   â”‚
â”‚  Output: Image keypoints (NÃ—2)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  5. HOMOGRAPHY ESTIMATION                       â”‚
â”‚  â€¢ Match to template keypoints                                  â”‚
â”‚  â€¢ RANSAC with cv2.findHomography                               â”‚
â”‚  â€¢ Temporal smoothing (EMA)                                     â”‚
â”‚  Output: H (3Ã—3), quality_score                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  6. VALIDATION                                  â”‚
â”‚  â€¢ Check inlier ratio                                           â”‚
â”‚  â€¢ Check corner bounds                                          â”‚
â”‚  â€¢ Check mask overlap                                           â”‚
â”‚  â€¢ Decide: accept or fallback                                   â”‚
â”‚  Output: Final H (3Ã—3), confidence                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       JSON OUTPUT                               â”‚
â”‚  {                                                              â”‚
â”‚    "mask": ...,                                                 â”‚
â”‚    "keypoints": {...},                                          â”‚
â”‚    "homography": [[...], [...], [...]],                         â”‚
â”‚    "quality_score": 0.93,                                       â”‚
â”‚    "confidence": {...}                                          â”‚
â”‚  }                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ File Structure for v2

```
atlas/
â”œâ”€â”€ v2/                          # NEW: v2 modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ processor_v2.py          # Main v2 processor
â”‚   â”‚
â”‚   â”œâ”€â”€ segmentation/            # NEW: DL segmentation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model_unet.py
â”‚   â”‚   â”œâ”€â”€ dataset.py
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ inference.py
â”‚   â”‚   â””â”€â”€ weights/
â”‚   â”‚       â””â”€â”€ best_model.pth
â”‚   â”‚
â”‚   â”œâ”€â”€ refinement/              # ENHANCED: Mask refinement
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ mask_refiner.py
â”‚   â”‚
â”‚   â”œâ”€â”€ homography/              # ENHANCED: Temporal smoothing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ estimator_v2.py
â”‚   â”‚   â””â”€â”€ smoother.py
â”‚   â”‚
â”‚   â””â”€â”€ validation/              # NEW: Quality checks
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ validator.py
â”‚
â”œâ”€â”€ detection/                   # REUSED from v1
â”‚   â”œâ”€â”€ line_detector.py
â”‚   â”œâ”€â”€ circle_detector.py
â”‚   â””â”€â”€ corner_detector.py
â”‚
â”œâ”€â”€ calibration/                 # REUSED from v1
â”‚   â””â”€â”€ ransac.py
â”‚
â””â”€â”€ coordinates/                 # REUSED from v1
    â””â”€â”€ transformer.py
```

---

## ğŸ¯ Performance Targets

| Metric | v1 (Current) | v2 (Target) | How to Measure |
|--------|--------------|-------------|----------------|
| Pitch IoU | 0.60-0.70 | â‰¥0.90 | Compare mask vs ground truth |
| Detection Rate | ~70% | â‰¥95% | Successful homography frames |
| Processing Time | 800ms | <1000ms | GPU inference |
| Temporal Stability | Poor | Â±2px | StdDev of corner positions |
| Lighting Robustness | Fails often | Works always | Day/night test suite |

---

## ğŸ§ª Validation Strategy

### 1. **Unit Tests**
- Segmentation: IoU on test set
- Line detection: Precision/recall on annotated lines
- Homography: Reprojection error < 5px

### 2. **Integration Tests**
- Full pipeline on 100-frame test video
- Measure frame-to-frame stability
- Visual inspection of overlays

### 3. **Production Tests**
- Run on full Egyptian league matches (multiple stadiums)
- Compare v1 vs v2 detection rates
- User acceptance testing

---

## ğŸš€ Migration Path

**Phase 1: Parallel Development** (Week 1-2)
- Keep v1 running
- Build v2 in separate directory
- Train initial segmentation model

**Phase 2: Alpha Testing** (Week 3)
- Run v2 on test videos
- Compare outputs side-by-side
- Fix major issues

**Phase 3: Beta Deployment** (Week 4)
- Deploy v2 to staging environment
- Run both v1 and v2, log differences
- Tune parameters

**Phase 4: Production Cutover** (Week 5)
- Switch production traffic to v2
- Keep v1 as fallback
- Monitor for 1 week

**Phase 5: v1 Deprecation** (Week 6)
- Remove v1 code
- Archive v1 documentation
- Full v2 production

---

## ğŸ” Legal & Licensing

**Training Data:**
- Egyptian league footage: Verify broadcast rights
- Self-recorded training field footage: âœ… 100% yours
- Annotated masks: âœ… Your IP

**Model Weights:**
- Trained on your data: âœ… You own them
- Can use commercially: âœ… Yes
- Can sell/license: âœ… Yes

**Code:**
- UNet architecture: Public domain (you implement)
- Training pipeline: âœ… Your code
- OpenCV usage: âœ… BSD license (commercial-friendly)

---

## ğŸ“š References

- **UNet Paper:** [Ronneberger et al., 2015](https://arxiv.org/abs/1505.04597)
- **Semantic Segmentation:** [Long et al., 2015](https://arxiv.org/abs/1411.4038)
- **Homography Estimation:** [Hartley & Zisserman, 2004]
- **Temporal Filtering:** Kalman Filter tutorial

---

## âœ… Deliverables Checklist

- [ ] Trained UNet model (best_model.pth)
- [ ] v2 processor implementation (processor_v2.py)
- [ ] Segmentation inference wrapper (inference.py)
- [ ] Homography temporal smoother (smoother.py)
- [ ] Validation module (validator.py)
- [ ] Training dataset (500+ annotated frames)
- [ ] Unit tests for all v2 modules
- [ ] Integration test suite
- [ ] Performance benchmark report
- [ ] Migration guide for users

---

**Document Version:** 1.0  
**Last Updated:** October 2024  
**Author:** NovaVista Team  
**Status:** Architecture Finalized, Implementation In Progress
